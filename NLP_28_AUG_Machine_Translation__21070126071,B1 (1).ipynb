{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT91WiJFwo7C"
      },
      "source": [
        "Name- ROHAN SARASWAT <br>\n",
        "PRN- 21070126071 <br>\n",
        "AIML B1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qcfzuvbtbd0D"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense,RepeatVector,TimeDistributed,Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from string import digits\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV6j_T7ldb18",
        "outputId": "5d16ec28-aee8-4397-d282-e74430807a6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tides        50000\n",
              "ted          39881\n",
              "indic2012    37726\n",
              "Name: source, dtype: int64"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/NLP Lab/Hindi_English_Truncated_Corpus.csv')\n",
        "#data=pd.read_csv(\"C:\\\\Users\\\\sah-1\\\\Downloads\\\\Hindi_English_Truncated_Corpus.csv\")\n",
        "data['source'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKyvmtBVixfh"
      },
      "outputs": [],
      "source": [
        "data=data[(data.english_sentence.apply(lambda x:len(str(x))<= 30))&\n",
        "          (data.hindi_sentence.apply(lambda x:len(str(x))<=30))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "667jjiWAep5P",
        "outputId": "bcdab352-7f5f-4361-8966-aa980730fd13"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-09406c50479e>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['english_sentence']=data['english_sentence'].apply(lambda x: str(x).lower())\n",
            "<ipython-input-4-09406c50479e>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.lower())\n"
          ]
        }
      ],
      "source": [
        "##changing uppercase to lowercase\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x: str(x).lower())\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8oRMCiUfR4n",
        "outputId": "f4951693-d562-4f5e-c8b5-aed80f11be11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-4c8c98c3bbe8>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['english_sentence']=data['english_sentence'].apply(lambda x: re.sub(\"'\",'',x))\n",
            "<ipython-input-5-4c8c98c3bbe8>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: re.sub(\"'\",'',x))\n"
          ]
        }
      ],
      "source": [
        "#Remove quotes\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x: re.sub(\"'\",'',x))\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: re.sub(\"'\",'',x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok1RIE40gssB",
        "outputId": "5a903f61-699b-40aa-da1e-d23f99a68e61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Punctuations to exclude::  {'~', '.', '`', '<', '@', '!', '#', '\\\\', '*', ')', ':', '+', ';', '|', '}', '_', '%', ']', \"'\", '&', '-', '^', '[', '>', '{', '$', '=', '/', '(', '\"', '?', ','}\n"
          ]
        }
      ],
      "source": [
        "to_exclude=set(string.punctuation)#set of all special characters\n",
        "print(\"Punctuations to exclude:: \",to_exclude)\n",
        "#remove all the special characters\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x:''.join(ch for ch in x if ch not in to_exclude))\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x:''.join(ch for ch in x if ch not in to_exclude))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cc0nRqOUHLjz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvFcNHdmhx2S"
      },
      "outputs": [],
      "source": [
        "from string import digits\n",
        "#Remove all numbers from text\n",
        "remove_digits=str.maketrans('','',digits)\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x:x.translate(remove_digits))\n",
        "\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x:x.translate(remove_digits))\n",
        "\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x:re.sub(\"[०१२३४५६७८९]\",\"\",x))\n",
        "\n",
        "#Remove Extra Spaces\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x:x.strip())\n",
        "\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x:x.strip())\n",
        "\n",
        "data['english_sentence']=data['english_sentence'].apply(lambda x: re.sub(\" +\",\" \",x))\n",
        "\n",
        "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: re.sub(\" +\",\" \",x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5n36lI6_oUs7",
        "outputId": "388b72cc-e8da-402c-d19a-a98ee42343ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ff50ea35-d6e6-431c-b288-313d5dab70e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>category religious text</td>\n",
              "      <td>श्रेणीधर्मग्रन्थ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ted</td>\n",
              "      <td>this changed slowly</td>\n",
              "      <td>धीरे धीरे ये सब बदला</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>ted</td>\n",
              "      <td>were being produced</td>\n",
              "      <td>उत्पन्न नहीं कि जाती थी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>maine</td>\n",
              "      <td>मेन</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>ted</td>\n",
              "      <td>can you imagine saying that</td>\n",
              "      <td>क्या आप ये कल्पना कर सकते है</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff50ea35-d6e6-431c-b288-313d5dab70e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff50ea35-d6e6-431c-b288-313d5dab70e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff50ea35-d6e6-431c-b288-313d5dab70e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7fc809c3-cebb-42ff-8170-fb315c6f128f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fc809c3-cebb-42ff-8170-fb315c6f128f')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7fc809c3-cebb-42ff-8170-fb315c6f128f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       source             english_sentence                hindi_sentence\n",
              "11  indic2012      category religious text              श्रेणीधर्मग्रन्थ\n",
              "23        ted          this changed slowly          धीरे धीरे ये सब बदला\n",
              "26        ted          were being produced       उत्पन्न नहीं कि जाती थी\n",
              "33  indic2012                        maine                           मेन\n",
              "35        ted  can you imagine saying that  क्या आप ये कल्पना कर सकते है"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvd0aQNMoW6F"
      },
      "outputs": [],
      "source": [
        "input_text=[]\n",
        "target_text=[]\n",
        "input_characters=set()\n",
        "target_characters=set()\n",
        "for eng,hin in data[['english_sentence','hindi_sentence']].itertuples(index=False):\n",
        "  target='START_ '+hin+' _END' #end sequence\n",
        "  input_text.append(eng)\n",
        "  target_text.append(target)\n",
        "  for eng_char in eng.split():\n",
        "    if eng_char not in input_characters:\n",
        "      input_characters.add(eng_char)\n",
        "  for hin_char in hin.split():\n",
        "    if hin_char not in target_characters:\n",
        "      target_characters.add(hin_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cc_buaeqAFy",
        "outputId": "69de22d1-ed8e-4914-ab2a-1868be1db3e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18416\n",
            "18416\n",
            "9232\n",
            "8665\n"
          ]
        }
      ],
      "source": [
        "print(len(input_text))\n",
        "print(len(target_text))\n",
        "print(len(input_characters))\n",
        "print(len(target_characters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpkIbKQ7qUD4",
        "outputId": "786decdd-cc9f-4514-e33f-938af7354b1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Text ->>>>>category religious text->>>>>>> Output Text ->>>>>>>START_ श्रेणीधर्मग्रन्थ _END\n"
          ]
        }
      ],
      "source": [
        "print(\"Input Text ->>>>>\"+input_text[0] +\"->>>>>>> Output Text ->>>>>>>\"+target_text[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNmWzOC0q42b"
      },
      "outputs": [],
      "source": [
        "input_char=sorted(list(input_characters))\n",
        "target_char=sorted(list(target_characters))\n",
        "\n",
        "num_encoder_tokens=len(input_characters)\n",
        "num_decoder_tokens=len(target_characters)+1\n",
        "\n",
        "max_encoder_seq_length=max([len(txt) for txt in input_text])\n",
        "max_decoder_seq_length=max([len(txt) for txt in target_text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLJE16D2rw9n",
        "outputId": "0d1cb82d-ce98-4832-c66c-a12afcae4fa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples: 18416\n",
            "Number of Unique input tokens: 9232\n",
            "Number of Unique output tokens: 8666\n",
            "Max Sequence length for inputs: 30\n",
            "Max Sequence length for outputs: 42\n"
          ]
        }
      ],
      "source": [
        "print('Number of samples:',len(input_text))\n",
        "print('Number of Unique input tokens:',num_encoder_tokens)\n",
        "print('Number of Unique output tokens:',num_decoder_tokens)\n",
        "print('Max Sequence length for inputs:',max_encoder_seq_length)\n",
        "print('Max Sequence length for outputs:',max_decoder_seq_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8zWcPhhtKgB"
      },
      "outputs": [],
      "source": [
        "input_token_index=dict([(word,i+1) for i,word in enumerate(input_char)])\n",
        "target_token_index=dict([(word,i+1) for i,word in enumerate(target_char)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CbzO2llu_gl"
      },
      "outputs": [],
      "source": [
        "reverse_input_char_index=dict((i,word) for word,i in input_token_index.items())\n",
        "reverse_target_char_index=dict((i, word) for word, i in target_token_index.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNqp5wiWv6G7",
        "outputId": "2e1f7233-c12d-4c52-a15d-98846bc45458"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((16574,), (1842,))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X,y=data.english_sentence,data.hindi_sentence\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=2)\n",
        "X_train.shape,X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BI5iRhjtwcPf"
      },
      "outputs": [],
      "source": [
        "def generate_batch(X,y,batch_size):\n",
        "  while True:\n",
        "    for j in range(0,len(X),batch_size):\n",
        "      encoder_input_data=np.zeros((batch_size,max_encoder_seq_length),dtype='float32')\n",
        "      decoder_input_data=np.zeros((batch_size,max_decoder_seq_length),dtype='float32')\n",
        "      decoder_target_data=np.zeros((batch_size,max_decoder_seq_length,num_decoder_tokens),dtype='float32')\n",
        "\n",
        "      for i,(input_text,target_text) in enumerate(zip(X[j:j+batch_size],y[j:j+batch_size])):\n",
        "        for t,word in enumerate(input_text.split()):\n",
        "          encoder_input_data[i,t]=input_token_index[word] #encoder input sequence\n",
        "        for t,word in enumerate(target_text.split()):\n",
        "          if t<len(target_text.split())-1:\n",
        "            decoder_input_data[i,t]=target_token_index[word] #decoder input sequence\n",
        "          if t>0:\n",
        "            decoder_target_data[i,t-1,target_token_index[word]]=1.\n",
        "      yield([encoder_input_data,decoder_input_data],decoder_target_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7dssGQf1CaY"
      },
      "outputs": [],
      "source": [
        "latent_dim=50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rr8vMg8V6US4"
      },
      "outputs": [],
      "source": [
        "#Encoder\n",
        "encoder_inputs=Input(shape=(None,))\n",
        "enc_emb=Embedding(num_encoder_tokens,latent_dim,mask_zero=True)(encoder_inputs)\n",
        "encoder_lstm=LSTM(latent_dim,return_state=True)\n",
        "encoder_outputs,state_h,state_c=encoder_lstm(enc_emb)\n",
        "\n",
        "encoder_states=[state_h,state_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tlu3DUS8UDA"
      },
      "outputs": [],
      "source": [
        "#Decoder\n",
        "decoder_inputs=Input(shape=(None,))\n",
        "dec_emb_layer=Embedding(num_decoder_tokens,latent_dim,mask_zero=True)\n",
        "dec_emb=dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm=LSTM(latent_dim,return_sequences=True,return_state=True)\n",
        "decoder_outputs,_, _=decoder_lstm(dec_emb,initial_state=encoder_states)\n",
        "decoder_dense=Dense(num_decoder_tokens,activation='softmax')\n",
        "decoder_outputs=decoder_dense(decoder_outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGDrDU-J-8lO"
      },
      "outputs": [],
      "source": [
        "model=Model([encoder_inputs,decoder_inputs],decoder_outputs)\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZj3vTec_aPA",
        "outputId": "5de95c34-06c2-4e95-a853-a7b25e2fd734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, None, 50)             461600    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 50)             433300    ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, 50),                 20200     ['embedding[0][0]']           \n",
            "                              (None, 50),                                                         \n",
            "                              (None, 50)]                                                         \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, None, 50),           20200     ['embedding_1[0][0]',         \n",
            "                              (None, 50),                            'lstm[0][1]',                \n",
            "                              (None, 50)]                            'lstm[0][2]']                \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, None, 8666)           441966    ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1377266 (5.25 MB)\n",
            "Trainable params: 1377266 (5.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fC3h7I6K_cMZ"
      },
      "outputs": [],
      "source": [
        "train_samples=len(X_train)\n",
        "val_samples=len(X_test)\n",
        "batch_size=16\n",
        "epochs=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-efX__-ByoY",
        "outputId": "8aa2e89c-496c-42f4-a630-910e94fab2a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-24-455b2635b9a0>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator=generate_batch(X_train,y_train,batch_size=batch_size),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1035/1035 [==============================] - 218s 197ms/step - loss: 7.2972 - acc: 0.0476 - val_loss: 6.9997 - val_acc: 0.0611\n",
            "Epoch 2/100\n",
            "1035/1035 [==============================] - 189s 182ms/step - loss: 6.5761 - acc: 0.0661 - val_loss: 6.7742 - val_acc: 0.0820\n",
            "Epoch 3/100\n",
            "1035/1035 [==============================] - 183s 176ms/step - loss: 6.1172 - acc: 0.0918 - val_loss: 6.6119 - val_acc: 0.1050\n",
            "Epoch 4/100\n",
            "1035/1035 [==============================] - 179s 173ms/step - loss: 5.6871 - acc: 0.1226 - val_loss: 6.4706 - val_acc: 0.1260\n",
            "Epoch 5/100\n",
            "1035/1035 [==============================] - 184s 178ms/step - loss: 5.3077 - acc: 0.1499 - val_loss: 6.4199 - val_acc: 0.1419\n",
            "Epoch 6/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 4.9699 - acc: 0.1808 - val_loss: 6.3762 - val_acc: 0.1574\n",
            "Epoch 7/100\n",
            "1035/1035 [==============================] - 184s 177ms/step - loss: 4.6566 - acc: 0.2142 - val_loss: 6.3548 - val_acc: 0.1681\n",
            "Epoch 8/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 4.3626 - acc: 0.2495 - val_loss: 6.3149 - val_acc: 0.1798\n",
            "Epoch 9/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 4.0823 - acc: 0.2838 - val_loss: 6.3137 - val_acc: 0.1979\n",
            "Epoch 10/100\n",
            "1035/1035 [==============================] - 184s 178ms/step - loss: 3.8160 - acc: 0.3198 - val_loss: 6.3092 - val_acc: 0.2120\n",
            "Epoch 11/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 3.5609 - acc: 0.3561 - val_loss: 6.3557 - val_acc: 0.2214\n",
            "Epoch 12/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 3.3242 - acc: 0.3907 - val_loss: 6.3834 - val_acc: 0.2318\n",
            "Epoch 13/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 3.1004 - acc: 0.4240 - val_loss: 6.4103 - val_acc: 0.2426\n",
            "Epoch 14/100\n",
            "1035/1035 [==============================] - 178s 172ms/step - loss: 2.8919 - acc: 0.4529 - val_loss: 6.4352 - val_acc: 0.2456\n",
            "Epoch 15/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 2.6958 - acc: 0.4842 - val_loss: 6.4875 - val_acc: 0.2523\n",
            "Epoch 16/100\n",
            "1035/1035 [==============================] - 178s 172ms/step - loss: 2.5143 - acc: 0.5155 - val_loss: 6.5282 - val_acc: 0.2529\n",
            "Epoch 17/100\n",
            "1035/1035 [==============================] - 178s 172ms/step - loss: 2.3421 - acc: 0.5469 - val_loss: 6.5590 - val_acc: 0.2573\n",
            "Epoch 18/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 2.1863 - acc: 0.5767 - val_loss: 6.5972 - val_acc: 0.2598\n",
            "Epoch 19/100\n",
            "1035/1035 [==============================] - 175s 169ms/step - loss: 2.0349 - acc: 0.6089 - val_loss: 6.6439 - val_acc: 0.2606\n",
            "Epoch 20/100\n",
            "1035/1035 [==============================] - 176s 170ms/step - loss: 1.8963 - acc: 0.6349 - val_loss: 6.6758 - val_acc: 0.2655\n",
            "Epoch 21/100\n",
            "1035/1035 [==============================] - 182s 176ms/step - loss: 1.7741 - acc: 0.6578 - val_loss: 6.7538 - val_acc: 0.2622\n",
            "Epoch 22/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 1.6550 - acc: 0.6788 - val_loss: 6.7979 - val_acc: 0.2642\n",
            "Epoch 23/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 1.5432 - acc: 0.6996 - val_loss: 6.8632 - val_acc: 0.2650\n",
            "Epoch 24/100\n",
            "1035/1035 [==============================] - 185s 179ms/step - loss: 1.4424 - acc: 0.7189 - val_loss: 6.9053 - val_acc: 0.2647\n",
            "Epoch 25/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 1.3520 - acc: 0.7340 - val_loss: 6.9554 - val_acc: 0.2636\n",
            "Epoch 26/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 1.2691 - acc: 0.7480 - val_loss: 7.0090 - val_acc: 0.2661\n",
            "Epoch 27/100\n",
            "1035/1035 [==============================] - 185s 179ms/step - loss: 1.1890 - acc: 0.7659 - val_loss: 7.0891 - val_acc: 0.2624\n",
            "Epoch 28/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 1.1189 - acc: 0.7784 - val_loss: 7.1568 - val_acc: 0.2600\n",
            "Epoch 29/100\n",
            "1035/1035 [==============================] - 182s 176ms/step - loss: 1.0503 - acc: 0.7897 - val_loss: 7.2342 - val_acc: 0.2600\n",
            "Epoch 30/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 0.9903 - acc: 0.8020 - val_loss: 7.3142 - val_acc: 0.2582\n",
            "Epoch 31/100\n",
            "1035/1035 [==============================] - 183s 177ms/step - loss: 0.9363 - acc: 0.8120 - val_loss: 7.3857 - val_acc: 0.2633\n",
            "Epoch 32/100\n",
            "1035/1035 [==============================] - 186s 179ms/step - loss: 0.8879 - acc: 0.8209 - val_loss: 7.4154 - val_acc: 0.2558\n",
            "Epoch 33/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 0.8325 - acc: 0.8313 - val_loss: 7.5048 - val_acc: 0.2556\n",
            "Epoch 34/100\n",
            "1035/1035 [==============================] - 183s 176ms/step - loss: 0.7893 - acc: 0.8409 - val_loss: 7.5594 - val_acc: 0.2586\n",
            "Epoch 35/100\n",
            "1035/1035 [==============================] - 186s 179ms/step - loss: 0.7482 - acc: 0.8485 - val_loss: 7.6201 - val_acc: 0.2586\n",
            "Epoch 36/100\n",
            "1035/1035 [==============================] - 182s 176ms/step - loss: 0.7102 - acc: 0.8554 - val_loss: 7.6651 - val_acc: 0.2591\n",
            "Epoch 37/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 0.6763 - acc: 0.8616 - val_loss: 7.7361 - val_acc: 0.2557\n",
            "Epoch 38/100\n",
            "1035/1035 [==============================] - 185s 179ms/step - loss: 0.6425 - acc: 0.8685 - val_loss: 7.8087 - val_acc: 0.2525\n",
            "Epoch 39/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 0.6053 - acc: 0.8751 - val_loss: 7.8792 - val_acc: 0.2509\n",
            "Epoch 40/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 0.5753 - acc: 0.8829 - val_loss: 7.9224 - val_acc: 0.2505\n",
            "Epoch 41/100\n",
            "1035/1035 [==============================] - 182s 176ms/step - loss: 0.5526 - acc: 0.8865 - val_loss: 8.0165 - val_acc: 0.2494\n",
            "Epoch 42/100\n",
            "1035/1035 [==============================] - 178s 172ms/step - loss: 0.5259 - acc: 0.8901 - val_loss: 8.0383 - val_acc: 0.2504\n",
            "Epoch 43/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 0.4976 - acc: 0.8972 - val_loss: 8.0961 - val_acc: 0.2529\n",
            "Epoch 44/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 0.4742 - acc: 0.9025 - val_loss: 8.1637 - val_acc: 0.2495\n",
            "Epoch 45/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 0.4574 - acc: 0.9060 - val_loss: 8.2260 - val_acc: 0.2487\n",
            "Epoch 46/100\n",
            "1035/1035 [==============================] - 179s 173ms/step - loss: 0.4347 - acc: 0.9105 - val_loss: 8.3204 - val_acc: 0.2451\n",
            "Epoch 47/100\n",
            "1035/1035 [==============================] - 183s 177ms/step - loss: 0.4124 - acc: 0.9169 - val_loss: 8.3690 - val_acc: 0.2463\n",
            "Epoch 48/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 0.3903 - acc: 0.9207 - val_loss: 8.4479 - val_acc: 0.2462\n",
            "Epoch 49/100\n",
            "1035/1035 [==============================] - 182s 175ms/step - loss: 0.3731 - acc: 0.9249 - val_loss: 8.5002 - val_acc: 0.2467\n",
            "Epoch 50/100\n",
            "1035/1035 [==============================] - 183s 177ms/step - loss: 0.3592 - acc: 0.9269 - val_loss: 8.5577 - val_acc: 0.2481\n",
            "Epoch 51/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 0.3392 - acc: 0.9317 - val_loss: 8.5892 - val_acc: 0.2454\n",
            "Epoch 52/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 0.3284 - acc: 0.9335 - val_loss: 8.6715 - val_acc: 0.2419\n",
            "Epoch 53/100\n",
            "1035/1035 [==============================] - 182s 176ms/step - loss: 0.3146 - acc: 0.9371 - val_loss: 8.6747 - val_acc: 0.2493\n",
            "Epoch 54/100\n",
            "1035/1035 [==============================] - 179s 173ms/step - loss: 0.2997 - acc: 0.9385 - val_loss: 8.7758 - val_acc: 0.2465\n",
            "Epoch 55/100\n",
            "1035/1035 [==============================] - 181s 174ms/step - loss: 0.2832 - acc: 0.9437 - val_loss: 8.7997 - val_acc: 0.2487\n",
            "Epoch 56/100\n",
            "1035/1035 [==============================] - 182s 176ms/step - loss: 0.2769 - acc: 0.9443 - val_loss: 8.8940 - val_acc: 0.2478\n",
            "Epoch 57/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 0.2600 - acc: 0.9477 - val_loss: 8.9582 - val_acc: 0.2449\n",
            "Epoch 58/100\n",
            "1035/1035 [==============================] - 179s 173ms/step - loss: 0.2539 - acc: 0.9494 - val_loss: 9.0110 - val_acc: 0.2494\n",
            "Epoch 59/100\n",
            "1035/1035 [==============================] - 182s 176ms/step - loss: 0.2403 - acc: 0.9528 - val_loss: 9.0665 - val_acc: 0.2439\n",
            "Epoch 60/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 0.2282 - acc: 0.9555 - val_loss: 9.0993 - val_acc: 0.2471\n",
            "Epoch 61/100\n",
            "1035/1035 [==============================] - 179s 173ms/step - loss: 0.2235 - acc: 0.9560 - val_loss: 9.1779 - val_acc: 0.2446\n",
            "Epoch 62/100\n",
            "1035/1035 [==============================] - 184s 178ms/step - loss: 0.2114 - acc: 0.9572 - val_loss: 9.1814 - val_acc: 0.2482\n",
            "Epoch 63/100\n",
            "1035/1035 [==============================] - 183s 177ms/step - loss: 0.2047 - acc: 0.9591 - val_loss: 9.2616 - val_acc: 0.2455\n",
            "Epoch 64/100\n",
            "1035/1035 [==============================] - 182s 176ms/step - loss: 0.1932 - acc: 0.9615 - val_loss: 9.2971 - val_acc: 0.2482\n",
            "Epoch 65/100\n",
            "1035/1035 [==============================] - 185s 179ms/step - loss: 0.1826 - acc: 0.9645 - val_loss: 9.3746 - val_acc: 0.2466\n",
            "Epoch 66/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 0.1740 - acc: 0.9668 - val_loss: 9.4314 - val_acc: 0.2438\n",
            "Epoch 67/100\n",
            "1035/1035 [==============================] - 183s 177ms/step - loss: 0.1758 - acc: 0.9660 - val_loss: 9.4847 - val_acc: 0.2490\n",
            "Epoch 68/100\n",
            "1035/1035 [==============================] - 185s 178ms/step - loss: 0.1668 - acc: 0.9673 - val_loss: 9.5338 - val_acc: 0.2470\n",
            "Epoch 69/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 0.1556 - acc: 0.9699 - val_loss: 9.5759 - val_acc: 0.2510\n",
            "Epoch 70/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 0.1498 - acc: 0.9707 - val_loss: 9.6046 - val_acc: 0.2474\n",
            "Epoch 71/100\n",
            "1035/1035 [==============================] - 183s 177ms/step - loss: 0.1552 - acc: 0.9699 - val_loss: 9.6405 - val_acc: 0.2533\n",
            "Epoch 72/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 0.1422 - acc: 0.9732 - val_loss: 9.7080 - val_acc: 0.2466\n",
            "Epoch 73/100\n",
            "1035/1035 [==============================] - 181s 174ms/step - loss: 0.1306 - acc: 0.9757 - val_loss: 9.7194 - val_acc: 0.2467\n",
            "Epoch 74/100\n",
            "1035/1035 [==============================] - 186s 179ms/step - loss: 0.1363 - acc: 0.9745 - val_loss: 9.8030 - val_acc: 0.2502\n",
            "Epoch 75/100\n",
            "1035/1035 [==============================] - 182s 176ms/step - loss: 0.1261 - acc: 0.9764 - val_loss: 9.8364 - val_acc: 0.2449\n",
            "Epoch 76/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 0.1217 - acc: 0.9765 - val_loss: 9.8942 - val_acc: 0.2479\n",
            "Epoch 77/100\n",
            "1035/1035 [==============================] - 182s 176ms/step - loss: 0.1149 - acc: 0.9785 - val_loss: 9.9276 - val_acc: 0.2472\n",
            "Epoch 78/100\n",
            "1035/1035 [==============================] - 179s 173ms/step - loss: 0.1072 - acc: 0.9804 - val_loss: 9.9767 - val_acc: 0.2478\n",
            "Epoch 79/100\n",
            "1035/1035 [==============================] - 179s 173ms/step - loss: 0.1024 - acc: 0.9818 - val_loss: 9.9977 - val_acc: 0.2497\n",
            "Epoch 80/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 0.0983 - acc: 0.9826 - val_loss: 10.1516 - val_acc: 0.2458\n",
            "Epoch 81/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 0.0990 - acc: 0.9808 - val_loss: 10.1419 - val_acc: 0.2411\n",
            "Epoch 82/100\n",
            "1035/1035 [==============================] - 179s 173ms/step - loss: 0.0977 - acc: 0.9813 - val_loss: 10.1957 - val_acc: 0.2401\n",
            "Epoch 83/100\n",
            "1035/1035 [==============================] - 179s 173ms/step - loss: 0.0906 - acc: 0.9835 - val_loss: 10.2046 - val_acc: 0.2461\n",
            "Epoch 84/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 0.0902 - acc: 0.9843 - val_loss: 10.2868 - val_acc: 0.2436\n",
            "Epoch 85/100\n",
            "1035/1035 [==============================] - 179s 173ms/step - loss: 0.0818 - acc: 0.9851 - val_loss: 10.3405 - val_acc: 0.2429\n",
            "Epoch 86/100\n",
            "1035/1035 [==============================] - 179s 173ms/step - loss: 0.0830 - acc: 0.9852 - val_loss: 10.3621 - val_acc: 0.2430\n",
            "Epoch 87/100\n",
            "1035/1035 [==============================] - 182s 176ms/step - loss: 0.0820 - acc: 0.9848 - val_loss: 10.4041 - val_acc: 0.2490\n",
            "Epoch 88/100\n",
            "1035/1035 [==============================] - 178s 172ms/step - loss: 0.0770 - acc: 0.9854 - val_loss: 10.4539 - val_acc: 0.2481\n",
            "Epoch 89/100\n",
            "1035/1035 [==============================] - 179s 173ms/step - loss: 0.0708 - acc: 0.9874 - val_loss: 10.5194 - val_acc: 0.2435\n",
            "Epoch 90/100\n",
            "1035/1035 [==============================] - 179s 173ms/step - loss: 0.0691 - acc: 0.9881 - val_loss: 10.5466 - val_acc: 0.2440\n",
            "Epoch 91/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 0.0653 - acc: 0.9888 - val_loss: 10.6184 - val_acc: 0.2400\n",
            "Epoch 92/100\n",
            "1035/1035 [==============================] - 175s 169ms/step - loss: 0.0639 - acc: 0.9893 - val_loss: 10.6967 - val_acc: 0.2444\n",
            "Epoch 93/100\n",
            "1035/1035 [==============================] - 175s 170ms/step - loss: 0.0788 - acc: 0.9856 - val_loss: 10.6560 - val_acc: 0.2408\n",
            "Epoch 94/100\n",
            "1035/1035 [==============================] - 180s 174ms/step - loss: 0.0657 - acc: 0.9876 - val_loss: 10.6374 - val_acc: 0.2414\n",
            "Epoch 95/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 0.0575 - acc: 0.9897 - val_loss: 10.7557 - val_acc: 0.2450\n",
            "Epoch 96/100\n",
            "1035/1035 [==============================] - 181s 175ms/step - loss: 0.0522 - acc: 0.9911 - val_loss: 10.7725 - val_acc: 0.2424\n",
            "Epoch 97/100\n",
            "1035/1035 [==============================] - 186s 180ms/step - loss: 0.0507 - acc: 0.9918 - val_loss: 10.8430 - val_acc: 0.2427\n",
            "Epoch 98/100\n",
            "1035/1035 [==============================] - 184s 177ms/step - loss: 0.0572 - acc: 0.9895 - val_loss: 10.9239 - val_acc: 0.2402\n",
            "Epoch 99/100\n",
            "1035/1035 [==============================] - 182s 176ms/step - loss: 0.0568 - acc: 0.9893 - val_loss: 10.9955 - val_acc: 0.2425\n",
            "Epoch 100/100\n",
            "1035/1035 [==============================] - 182s 176ms/step - loss: 0.0498 - acc: 0.9917 - val_loss: 10.9433 - val_acc: 0.2412\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a7ed41abeb0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit_generator(generator=generate_batch(X_train,y_train,batch_size=batch_size),\n",
        "                    steps_per_epoch=train_samples//batch_size,epochs=epochs,\n",
        "                    validation_data=generate_batch(X_test,y_test,batch_size=batch_size),\n",
        "                    validation_steps=val_samples//batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm_w1oYpCiNm"
      },
      "outputs": [],
      "source": [
        "model.save_weights('nmt_eng_hin_translation.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lciBf7VqBl5u"
      },
      "source": [
        "Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UX16D53wCN5e"
      },
      "outputs": [],
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gexzcy5hCQCm"
      },
      "outputs": [],
      "source": [
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ospatMaRCSZ4"
      },
      "outputs": [],
      "source": [
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder␣sequence\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2,initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "# Final decoder model\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs,[decoder_outputs2] + decoder_states2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpZhHdhfCsh6"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # Encode the input as state vectors.\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "  target_seq = np.zeros((1,1))\n",
        "  # Populate the first character of target sequence with the start character.\n",
        "  #target_seq[0, 0] = target_token_index['START_ ']\n",
        "  # Sampling loop for a batch of sequences\n",
        "  # (to simplify, here we assume a batch of size 1).\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition:\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "    # Sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "    decoded_sentence += ' '+sampled_char\n",
        "    # Exit condition: either hit max length\n",
        "    # or find stop character.\n",
        "    if (sampled_char == ' _END' or len(decoded_sentence) > 25):\n",
        "      stop_condition = True\n",
        "    # Update the target sequence (of length 1).\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "    # Update states\n",
        "    states_value = [h, c]\n",
        "  return decoded_sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TBoCUFcDLUU"
      },
      "outputs": [],
      "source": [
        "val_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
        "k=-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K4czBEkEG9N",
        "outputId": "0b3845bb-a736-4040-cf2e-43fc1c3454a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Input English sentence: i have a little acorn here\n",
            "Actual Hindi Translation: मेरे पास एक छोटा सा बाँजफ़ल है\n",
            "Predicted Hindi Translation:  उल्लेख किया है । हुई थी आप”\n"
          ]
        }
      ],
      "source": [
        "k+=2\n",
        "(input_seq, actual_output), _ = next(val_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_test[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_test[k:k+1].values[0])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN7wI-fdIkLK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
