{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ROHAN SARASWAT, PRN- 21070126071\n",
        "AIML-B1. NLP ASSIGNMENT-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Starting with importing Neccessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVlKWkb71TdZ",
        "outputId": "83f3df2c-b388-40bb-dade-3c60a613dce2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = set(stopwords.words(\"english\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbjTphbBSn5X"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/DATASETS/IMDB Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "wnhkqA8BeZz7",
        "outputId": "7c336ea1-7555-441c-b3b7-4019f7956121"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-22a2bb1f-a5f6-480a-8f7c-dbbfec4f0183\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22a2bb1f-a5f6-480a-8f7c-dbbfec4f0183')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-22a2bb1f-a5f6-480a-8f7c-dbbfec4f0183 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-22a2bb1f-a5f6-480a-8f7c-dbbfec4f0183');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f88e1c7b-c986-49f5-be84-8a893ebb41cb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f88e1c7b-c986-49f5-be84-8a893ebb41cb')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f88e1c7b-c986-49f5-be84-8a893ebb41cb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2n1UGRMeb-s"
      },
      "outputs": [],
      "source": [
        "textdata=data['review']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO3uAgWmfqNC",
        "outputId": "9c930e02-7e5b-4ad0-da6e-a21a06aa5a3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        One of the other reviewers has mentioned that ...\n",
              "1        A wonderful little production. <br /><br />The...\n",
              "2        I thought this was a wonderful way to spend ti...\n",
              "3        Basically there's a family where a little boy ...\n",
              "4        Petter Mattei's \"Love in the Time of Money\" is...\n",
              "                               ...                        \n",
              "49995    I thought this movie did a down right good job...\n",
              "49996    Bad plot, bad dialogue, bad acting, idiotic di...\n",
              "49997    I am a Catholic taught in parochial elementary...\n",
              "49998    I'm going to have to disagree with the previou...\n",
              "49999    No one expects the Star Trek movies to be high...\n",
              "Name: review, Length: 50000, dtype: object"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "textdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZGNFk-Zg90G"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "# Cleaning of text data by performing neccessary procedures\n",
        "def clean_text(text):\n",
        "    # remove punctuations mark\n",
        "    text = ''.join(word for word in text if word not in string.punctuation)\n",
        "    text=''.join(word for word in text if word not in stopwords)\n",
        "    text=re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
        "    #text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # remove digits from data\n",
        "    text01 = ''.join(w.lower() for w in text if not w.isdigit())\n",
        "    # lower case of the data\n",
        "    #text2 = text1.lower()\n",
        "    # remove escape characters\n",
        "    REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "    # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text01 = REPLACE_BY_SPACE_RE.sub(' ',text01)\n",
        "    return text01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTlhDP7M3z2o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDGTQn4RFlvF"
      },
      "outputs": [],
      "source": [
        "# Lemmatization of text data\n",
        "def lemmatize_text(text):\n",
        "    wordlist = []\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    # Sentence tokenization\n",
        "    sentences = nltk.sent_tokenize(str(text))\n",
        "\n",
        "    intial_sentences = sentences[0:1]\n",
        "    final_sentences = sentences[len(sentences)-2: len(sentences)-1]\n",
        "\n",
        "    # Word tokenization on data\n",
        "    for sentence in intial_sentences:\n",
        "        words = nltk.word_tokenize(sentence)\n",
        "        for word in words:\n",
        "            wordlist.append(word)\n",
        "\n",
        "    for sentence in final_sentences:\n",
        "        words = nltk.word_tokenize(sentence)\n",
        "        for word in words:\n",
        "            wordlist.append(word)\n",
        "\n",
        "    return wordlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqAcsEbD4skC"
      },
      "outputs": [],
      "source": [
        "# Apply the functions on transcription column\n",
        "\n",
        "# Clean\n",
        "textdata = textdata.apply(lambda x: clean_text(x))\n",
        "# Lemmatize\n",
        "textdata = textdata.apply(lambda x: lemmatize_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Zcqz_NZ5FzG",
        "outputId": "8db612ca-01aa-4552-d7fc-6f2d9342c134"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        [one, f, he, her, revewer, h, enne, h, fer, wc...\n",
              "1        [a, wnerful, lle, prucn, br, br, the, flng, ec...\n",
              "2        [i, hugh, h, w, wnerful, w, pen, e, n, h, uer,...\n",
              "3        [bcll, here, fl, where, lle, b, jke, hnk, here...\n",
              "4        [peer, me, lve, n, he, te, f, mne, vull, unnng...\n",
              "                               ...                        \n",
              "49995    [i, hugh, h, ve, wn, rgh, g, jb, i, wn, creve,...\n",
              "49996    [b, pl, b, lgue, b, cng, c, recng, he, nnng, p...\n",
              "49997    [i, chlc, ugh, n, prchl, eleenr, chl, b, nun, ...\n",
              "49998    [i, gng, hve, gree, wh, he, prevu, cen, n, e, ...\n",
              "49999    [n, ne, expec, he, sr, trek, ve, be, hgh, r, b...\n",
              "Name: review, Length: 50000, dtype: object"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "textdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwmJi9gx6DFY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMYO0x8lATUG"
      },
      "outputs": [],
      "source": [
        "# Performing Vectorization: ON the Data\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hulJpmy9B3jp",
        "outputId": "2399e31c-210e-441f-fb84-2cc662502173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abb' 'abc' 'abu' ... 'zne' 'zng' 'zngl']\n"
          ]
        }
      ],
      "source": [
        "# Text to TFIDF values conversion:\n",
        "vectorizer = TfidfVectorizer(analyzer='word', stop_words='english',\n",
        "                             ngram_range=(1,3), max_df=0.75,\n",
        "                             min_df=5, use_idf=True,\n",
        "                             smooth_idf=True,max_features=5000)\n",
        "\n",
        "# Fit and transform\n",
        "tfIdfMat  = vectorizer.fit_transform(\" \".join(x) for x in textdata)\n",
        "\n",
        "# Feature names\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE-dEb1CCKTn"
      },
      "outputs": [],
      "source": [
        "# Performance measure For measures report\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECaCGrGiFR1G"
      },
      "outputs": [],
      "source": [
        "# Including neccessary Algorithms:\n",
        "algos=[('LR',LogisticRegression()),('SVM',SVC()),('RF',RandomForestClassifier())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB0XbLvNGzyU"
      },
      "outputs": [],
      "source": [
        "# Defining an function for the data:\n",
        "def nlpPipeline(algorithms,Xtrain,ytrain,Xtest,ytest):\n",
        "  for algo,classifier in algorithms:\n",
        "    pipeline=Pipeline([\n",
        "        (\"classifier\",classifier)\n",
        "    ])\n",
        "    pipeline.fit(Xtrain,ytrain)\n",
        "    ypredict=pipeline.predict(Xtest)\n",
        "    print(\"Classification Report for \"+algo)\n",
        "    print(classification_report(y_test,\n",
        "                                ypredict,\n",
        "\n",
        "                                zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GpcOYFKIhIJ"
      },
      "outputs": [],
      "source": [
        "# LabelEncoding y\n",
        "y=data['sentiment'].replace('negative',0).replace('positive',1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ipQpRzYI3-n",
        "outputId": "cf5cd9e3-cac4-44c9-d895-c7393b9027b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        1\n",
              "1        1\n",
              "2        1\n",
              "3        0\n",
              "4        1\n",
              "        ..\n",
              "49995    1\n",
              "49996    0\n",
              "49997    0\n",
              "49998    0\n",
              "49999    0\n",
              "Name: sentiment, Length: 50000, dtype: int64"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVANWtyQHFJy"
      },
      "outputs": [],
      "source": [
        "#train test spliit of thr tfidf dataset:\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfIdfMat,\n",
        "                                                    y,\n",
        "                                                    stratify=y,\n",
        "                                                    random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2UwNmm-HSOc",
        "outputId": "18825f10-571b-48d4-da8e-d6a0b87400b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification with TFIDF\n",
            "Classification Report for LR\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86      6250\n",
            "           1       0.86      0.86      0.86      6250\n",
            "\n",
            "    accuracy                           0.86     12500\n",
            "   macro avg       0.86      0.86      0.86     12500\n",
            "weighted avg       0.86      0.86      0.86     12500\n",
            "\n",
            "Classification Report for SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.87      6250\n",
            "           1       0.86      0.87      0.87      6250\n",
            "\n",
            "    accuracy                           0.87     12500\n",
            "   macro avg       0.87      0.87      0.87     12500\n",
            "weighted avg       0.87      0.87      0.87     12500\n",
            "\n",
            "Classification Report for RF\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.83      0.82      6250\n",
            "           1       0.83      0.80      0.81      6250\n",
            "\n",
            "    accuracy                           0.81     12500\n",
            "   macro avg       0.81      0.81      0.81     12500\n",
            "weighted avg       0.81      0.81      0.81     12500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Printing the results:\n",
        "print('Classification with TFIDF')\n",
        "nlpPipeline(algos,X_train,y_train,X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zX5P9NzJwBY"
      },
      "outputs": [],
      "source": [
        "# Importing another imp libraries\n",
        "mport gensim\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qIOSVOYSK3o"
      },
      "outputs": [],
      "source": [
        "# Importing the google vector model\n",
        "model=gensim.models.KeyedVectors.load_word2vec_format('/content/drive/My Drive/GoogleNews-vectors-negative300.bin',\n",
        "                                                      binary=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP7NU58ASMfA",
        "outputId": "d7ddb96c-c57f-4caf-be0b-d1c877c93dd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3000000\n"
          ]
        }
      ],
      "source": [
        "#vocabulary Collection:\n",
        "vocab=model.key_to_index\n",
        "print(len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNaPNwrTSRnP"
      },
      "outputs": [],
      "source": [
        "# Creating an Embeddings function:\n",
        "def embeddings(text):\n",
        "  DIM=300\n",
        "  zero_vec=np.zeros(DIM)\n",
        "  features=[]\n",
        "  for tokens in text:\n",
        "    feat=np.zeros(DIM)\n",
        "    count=0+1e-5 #for DIV by 0 error\n",
        "    for token in tokens:\n",
        "      if token in model:\n",
        "        feat+=model[token]\n",
        "        count +=1\n",
        "    if(count !=0):\n",
        "      features.append(feat/count)\n",
        "    else:\n",
        "      features.append(zero_vec)\n",
        "  return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYGwtI3XSVPk",
        "outputId": "a331e775-e9b7-4ece-832c-aedab5c1637f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50000\n"
          ]
        }
      ],
      "source": [
        "data_vec=embeddings(textdata)\n",
        "print(len(data_vec))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZxJZBmKSqu_"
      },
      "outputs": [],
      "source": [
        "# Spliting the data for Classifiction of word2Vec:\n",
        "Xw2v_train,Xw2v_test,yw2v_train,yw2v_test=train_test_split(data_vec,y,stratify=y,random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYK5On97Su4P",
        "outputId": "190d856f-582b-49fa-e837-bcd9b065b477"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification eith word2Vec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for LR\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.70      0.71      6250\n",
            "           1       0.71      0.72      0.71      6250\n",
            "\n",
            "    accuracy                           0.71     12500\n",
            "   macro avg       0.71      0.71      0.71     12500\n",
            "weighted avg       0.71      0.71      0.71     12500\n",
            "\n",
            "Classification Report for SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.72      0.72      6250\n",
            "           1       0.72      0.72      0.72      6250\n",
            "\n",
            "    accuracy                           0.72     12500\n",
            "   macro avg       0.72      0.72      0.72     12500\n",
            "weighted avg       0.72      0.72      0.72     12500\n",
            "\n",
            "Classification Report for RF\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.64      0.64      6250\n",
            "           1       0.64      0.64      0.64      6250\n",
            "\n",
            "    accuracy                           0.64     12500\n",
            "   macro avg       0.64      0.64      0.64     12500\n",
            "weighted avg       0.64      0.64      0.64     12500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Classification with the help of word2Vec')\n",
        "nlpPipeline(algos,Xw2v_train,yw2v_train,Xw2v_test,yw2v_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaE7SlV0aZ5g"
      },
      "source": [
        "### Using Count Vectorizer Model in Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02Hx6N7zcpXa"
      },
      "outputs": [],
      "source": [
        "# Assigining Values:\n",
        "text=data['review']\n",
        "text = text.apply(lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14qUuKq5SySw"
      },
      "outputs": [],
      "source": [
        "# assigining the values:\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vector=CountVectorizer()\n",
        "mat=vector.fit_transform(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSuC_oKTa2RM",
        "outputId": "dad0df97-e23e-48ff-cfbe-bc80b7ef302c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['aa', 'aaa', 'aaaaaaaaaaaahhhhhhhhhhhhhh', ..., 'þór', 'יגאל',\n",
              "       'כרמון'], dtype=object)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKtY71E6edVS"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(mat,y,stratify=y,random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht3iOeBKfIxt",
        "outputId": "167e31fc-703a-40fb-d01a-c88386ee3fe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification with count vectorizer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for LR\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86      6250\n",
            "           1       0.86      0.86      0.86      6250\n",
            "\n",
            "    accuracy                           0.86     12500\n",
            "   macro avg       0.86      0.86      0.86     12500\n",
            "weighted avg       0.86      0.86      0.86     12500\n",
            "\n",
            "Classification Report for SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.84      6250\n",
            "           1       0.84      0.85      0.84      6250\n",
            "\n",
            "    accuracy                           0.84     12500\n",
            "   macro avg       0.84      0.84      0.84     12500\n",
            "weighted avg       0.84      0.84      0.84     12500\n",
            "\n",
            "Classification Report for RF\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.84      0.83      6250\n",
            "           1       0.84      0.80      0.82      6250\n",
            "\n",
            "    accuracy                           0.82     12500\n",
            "   macro avg       0.82      0.82      0.82     12500\n",
            "weighted avg       0.82      0.82      0.82     12500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Printing the Report:\n",
        "\n",
        "print('Classification with Count Vectorizer')\n",
        "nlpPipeline(algos,X_train,y_train,X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXIR-gf_gAR5"
      },
      "outputs": [],
      "source": [
        "# So these were various results that had been found out by applying various models and functions on the text Data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
